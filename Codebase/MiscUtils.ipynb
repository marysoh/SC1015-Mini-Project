{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ef64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import FreqDist\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56aaedd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot_cloud()\n",
    "This function is used to display the word cloud of the words used in a given WordCloud object. \n",
    "\n",
    "@param word_cloud is the WordCloud object that we intend to display.\n",
    "'''\n",
    "\n",
    "def plot_cloud(word_cloud):\n",
    "    plt.figure(figsize = (40,30))\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ad26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "generateTopWords()\n",
    "\n",
    "This function is used to generate and display the most common words in ascending order.\n",
    "Nested within uses plot_cloud(). Refer to plot_cloud() for more information.\n",
    "\n",
    "@param k is the Category that we intend to analyse.\n",
    "@param v is the DataFrame associated with k.\n",
    "@param num is the maximum limit for the most common words that we want displayed.\n",
    "'''\n",
    "\n",
    "def generateTopWords(k, v, num):\n",
    "    \n",
    "    # Define a TitleDF for NLP Analysis\n",
    "    titleDF = pd.DataFrame(v[['Title', 'Views']])\n",
    "    print(\"This is the first 5 entries of the dataframe generated for the category \" + k)\n",
    "    display(titleDF.head())\n",
    "    \n",
    "    # Creating a SnowballStemmer object to stem the different words in the title for each video in the dataframe.\n",
    "    j = 0\n",
    "    Snow_Stemmer = SnowballStemmer(language = 'english')\n",
    "    for i in titleDF['Title']:\n",
    "        title = re.findall(r'[^\\W_]+', i.lower())\n",
    "        wordList = [w for w in title if w not in stopwords.words(\"english\")]\n",
    "        \n",
    "        stemmedList = []\n",
    "        for word in wordList:\n",
    "            stemmedWord = Snow_Stemmer.stem(word)\n",
    "            stemmedList.append(stemmedWord)\n",
    "        \n",
    "        titleDF['Title'].iloc[j] = stemmedList\n",
    "        j += 1\n",
    "        \n",
    "    \n",
    "    # Creating a list and appending all the words that have been stemmed prior.\n",
    "    WordList = []\n",
    "    for i in titleDF['Title']:\n",
    "        for word in range(len(i)):\n",
    "            WordList.append(i[word])\n",
    "\n",
    "    # Concatenating all the words in the list into one long chained string, separated by one whitespace.\n",
    "    string = ' '.join(WordList)\n",
    "    \n",
    "    # Generating the wordcloud of the words in the list.\n",
    "    wordcloud = WordCloud(width = 3000, height = 2000, random_state = 1, background_color = 'salmon', colormap = 'Pastel1', collocations = False).generate(string)\n",
    "    plot_cloud(wordcloud)\n",
    "    \n",
    "    # Generating the frequency distribution of the Top \"Num\" words\n",
    "    data = FreqDist(WordList)\n",
    "    topWords = pd.DataFrame(data.most_common(num), columns = [\"Word\", \"Occurrence\"])\n",
    "    display(topWords.head(20))\n",
    "    \n",
    "    return topWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533f8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calUpperLowerBound()\n",
    "This function is used to calculate the upper (1.5 * IQR + Q3) and lower (Q1 - 1.5 * IQR) bound of a numerical dataset.\n",
    "\n",
    "@param DF is the numerical dataset that we want to calculate.\n",
    "\n",
    "@return upper is the upper bound of the dataset.\n",
    "@return lower is the lower bound of the dataset.\n",
    "'''\n",
    "\n",
    "def calUpperLowerBound(DF):\n",
    "    IQR = DF.quantile(0.75) - DF.quantile(0.25)\n",
    "    \n",
    "    upper = DF.quantile(0.75) + (1.5 * IQR)\n",
    "    lower = DF.quantile(0.25) - (1.5 * IQR)\n",
    "    \n",
    "    return upper, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bc6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calFPR()\n",
    "This function is used to calculate the False Positive Rate of a Prediction.\n",
    "\n",
    "@param y is the dataset of the response.\n",
    "@param y_pred is the predicted dataset of the response.\n",
    "\n",
    "@return this is the calculated False Positive Rate.\n",
    "'''\n",
    "\n",
    "def calFPR(y, y_pred):\n",
    "    matrix = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    return matrix[0][1] / (matrix[0][0] + matrix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ced605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calTPR()\n",
    "This function is used to calculate the True Positive Rate of a Prediction.\n",
    "\n",
    "@param y is the dataset of the response.\n",
    "@param y_pred is the predicted dataset of the response.\n",
    "\n",
    "@return this is the calculated True Positive Rate.\n",
    "'''\n",
    "\n",
    "def calTPR(y, y_pred):\n",
    "    matrix = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    return matrix[1][1] / (matrix[1][0] + matrix[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfccf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calFNR()\n",
    "This function is used to calculate the False Negative Rate of a Prediction.\n",
    "\n",
    "@param y is the dataset of the response.\n",
    "@param y_pred is the predicted dataset of the response.\n",
    "\n",
    "@return this is the calculated False Negative Rate.\n",
    "'''\n",
    "\n",
    "def calFNR(y, y_pred):\n",
    "    matrix = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    return matrix[1][0] / (matrix[1][0] + matrix[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3acd4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calTNR()\n",
    "This function is used to calculate the True Negative Rate of a Prediction.\n",
    "\n",
    "@param y is the dataset of the response.\n",
    "@param y_pred is the predicted dataset of the response.\n",
    "\n",
    "@return this is the calculated True Negative Rate.\n",
    "'''\n",
    "\n",
    "def calTNR(y, y_pred):\n",
    "    matrix = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    return matrix[0][0] / (matrix[0][0] + matrix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95803b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LRFuncByCat()\n",
    "This function is used to generate an entire Linear Regression Model specific to each category. It includes the \n",
    "train-test splitting of the dataset, the summary statistics of the data, plots out the associated figures, \n",
    "and prints out the goodness of fit of the given model.\n",
    "\n",
    "@param k is the Category that we intend to analyse.\n",
    "@param v is the DataFrame associated with k.\n",
    "\"\"\"\n",
    "\n",
    "def LRFuncByCat(k, v, random_state = 42):\n",
    "    x = pd.DataFrame(v[['Subscribers', 'Length', 'LengthOfTitle']])\n",
    "    y = pd.DataFrame(v['Views'])\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = random_state)\n",
    "    \n",
    "    print(\"This is the Train-Test Split for the data points categorised under \" + k)\n",
    "    print(\"Train Set :\", y_train.shape, x_train.shape)\n",
    "    print(\"Test Set  :\", y_test.shape, x_test.shape)\n",
    "    \n",
    "    print()\n",
    "    print(\"This is the Summary Statistics of our Train Dataset:\")\n",
    "    display(y_train.describe())\n",
    "    display(x_train.describe())\n",
    "    \n",
    "    print(\"\\nBelow plots the Boxplot, Histogram, and Violinplot of Views\")\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "    sb.boxplot(data = y_train, orient = \"h\", ax = axes[0])\n",
    "    sb.histplot(data = y_train, ax = axes[1])\n",
    "    sb.violinplot(data = y_train, orient = \"h\", ax = axes[2])\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nBelow plots the Boxplot, Histogram, and Violinplot of the following variables (in order): \")\n",
    "    print(\"(1) Subscribers\\n(2) Released\\n(3) Length\\n(4) LengthOfTitle\")\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(3, 3, figsize = (18, 12))\n",
    "    f.subplots_adjust(hspace = 0.5, wspace = 0.125)\n",
    "    count = 0\n",
    "    for var in x_train:\n",
    "        sb.boxplot(data = pd.DataFrame(x_train[var]), orient = \"h\", ax = axes[count, 0])\n",
    "        sb.histplot(data = pd.DataFrame(x_train[var]), ax = axes[count, 1])\n",
    "        sb.violinplot(data = pd.DataFrame(x_train[var]), orient = \"h\", ax = axes[count, 2])\n",
    "        count += 1\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nHere displays the heatmap and the Pairplot of all the variables in our Training Data\")\n",
    "    trainDF = pd.concat([y_train, x_train], axis = 1).reindex(y_train.index)\n",
    "    \n",
    "    plt.figure()\n",
    "    f = plt.figure(figsize = (12, 8))\n",
    "    sb.heatmap(trainDF.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")\n",
    "    plt.show()\n",
    "    \n",
    "    sb.pairplot(data = trainDF)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nThis is the Linear Regression Model based on videos that are categorised under \" + k)\n",
    "    linreg = LinearRegression()         # create the linear regression object\n",
    "    linreg.fit(x_train, y_train)        # train the linear regression model\n",
    "\n",
    "    # Coefficients of the Linear Regression line\n",
    "    print('Intercept of Regression \\t: b = ', linreg.intercept_)\n",
    "    print('Coefficients of Regression \\t: a = ', linreg.coef_)\n",
    "    print()\n",
    "\n",
    "    # Print the Coefficients against Predictors\n",
    "    pd.DataFrame(list(zip(x_train.columns, linreg.coef_[0])), columns = [\"Predictors\", \"Coefficients\"])\n",
    "\n",
    "    y_train_pred = linreg.predict(x_train)\n",
    "    y_test_pred = linreg.predict(x_test)\n",
    "\n",
    "    # Plot the Predictions vs the True values\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(1, 2, figsize = (24, 12))\n",
    "    axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "    axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "    axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "    axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "    axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "    axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "    axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "    axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "    print(\"Explained Variance (R^2) \\t:\", linreg.score(x_train, y_train))\n",
    "    print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "    print(\"Root Mean Squared Error (RMSE) \\t:\", mean_squared_error(y_train, y_train_pred, squared = False))\n",
    "    print()\n",
    "\n",
    "    print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "    print(\"Explained Variance (R^2) \\t:\", linreg.score(x_test, y_test))\n",
    "    print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"Root Mean Squared Error (RMSE) \\t:\", mean_squared_error(y_test, y_test_pred, squared = False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "513d78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LRFuncInGen()\n",
    "This function is used to generate an entire Linear Regression Model in general, narrowing to one predictor. \n",
    "It includes the train-test splitting of the dataset, the summary statistics of the data, plots out the associated \n",
    "figures, and prints out the goodness of fit of the given model.\n",
    "\n",
    "@param DF is the dataframe that we intend to analyse.\n",
    "@param predictor is the predictor variable used.\n",
    "@param response is the response variable that will be predicted.\n",
    "@param random_state is used to change the outcome of the train test split.\n",
    "\"\"\"\n",
    "\n",
    "def LRFuncInGen(DF, predictor, response, random_state):\n",
    "    subscribers = pd.DataFrame(DF[predictor])\n",
    "    views = pd.DataFrame(DF[response])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(subscribers, views, test_size = 0.20, random_state = random_state)\n",
    "    print(\"This is the Train-Test Split for the dataset:\")\n",
    "    print(\"Train Set :\", y_train.shape, X_train.shape)\n",
    "    print(\"Test Set  :\", y_test.shape, X_test.shape)\n",
    "    \n",
    "    print()\n",
    "    print(\"This is the Summary Statistics of our Train Dataset:\")\n",
    "    display(y_train.describe())\n",
    "    display(X_train.describe())\n",
    "    \n",
    "    print(\"\\nBelow plots the Boxplot, Histogram, and Violinplot of \" + response)\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(1, 3, figsize = (24, 6))\n",
    "    sb.boxplot(data = y_train, orient = \"h\", ax = axes[0])\n",
    "    sb.histplot(data = y_train, ax = axes[1])\n",
    "    sb.violinplot(data = y_train, orient = \"h\", ax = axes[2])\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nBelow plots the Boxplot, Histogram, and Violinplot of \" + predictor)\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(1, 3, figsize = (24, 6))\n",
    "    sb.boxplot(data = X_train, orient = \"h\", ax = axes[0])\n",
    "    sb.histplot(data = X_train, ax = axes[1])\n",
    "    sb.violinplot(data = X_train, orient = \"h\", ax = axes[2])\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nHere displays the heatmap and the Pairplot of all the variables in our Training Data\")\n",
    "    trainDF = pd.concat([y_train, X_train], axis = 1).reindex(y_train.index)\n",
    "    \n",
    "    plt.figure()\n",
    "    f = plt.figure(figsize = (12, 8))\n",
    "    sb.heatmap(trainDF.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")\n",
    "    plt.show()\n",
    "    \n",
    "    sb.pairplot(data = trainDF)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nThis is the Linear Regression Model predicting Views based on Subsribers in general\")\n",
    "    linreg = LinearRegression()         # create the linear regression object\n",
    "    linreg.fit(X_train, y_train)        # train the linear regression model\n",
    "    \n",
    "    # Coefficients of the Linear Regression line\n",
    "    print('Intercept of Regression \\t: b = ', linreg.intercept_)\n",
    "    print('Coefficients of Regression \\t: a = ', linreg.coef_)\n",
    "    print()\n",
    "\n",
    "    # Print the Coefficients against Predictors\n",
    "    pd.DataFrame(list(zip(X_train.columns, linreg.coef_[0])), columns = [\"Predictors\", \"Coefficients\"])\n",
    "\n",
    "    y_train_pred = linreg.predict(X_train)\n",
    "    y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "    # Plot the Predictions vs the True values\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(1, 2, figsize = (24, 12))\n",
    "    axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "    axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "    axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "    axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "    axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "    axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "    axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "    axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "    print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "    print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "    print(\"Root Mean Squared Error (RMSE) \\t:\", mean_squared_error(y_train, y_train_pred, squared = False))\n",
    "    print()\n",
    "\n",
    "    print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "    print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "    print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"Root Mean Squared Error (RMSE) \\t:\", mean_squared_error(y_test, y_test_pred, squared = False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b26d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DTFunc()\n",
    "This function is used to generate an entire Decision Tree Classification Model. It includes the train-test\n",
    "splitting of the dataset, plots out the associated figures, and prints out the goodness of fit of the given model.\n",
    "\n",
    "Nested within uses calFPR(), calFNR(), calTPR(), calTNR(). Refer to their respective cells for more information.\n",
    "\n",
    "@param k is the Category that we intend to analyse.\n",
    "@param v is the DataFrame associated with k.\n",
    "@param topWords is the list of most frequent words that appear in Titles.\n",
    "\"\"\"\n",
    "\n",
    "def DTFunc(k, v, topWords):\n",
    "    \n",
    "    # Creating a new column that includes the data generated from generateTopWords().\n",
    "    v['hasTop20'] = 0\n",
    "    for i in range(len(v)):\n",
    "        v['hasTop20'].iloc[i] = 0\n",
    "        for j in topWords['Word']:\n",
    "            if j in v['Title'].iloc[i]:\n",
    "                v['hasTop20'].iloc[i] = 1\n",
    "                break\n",
    "    \n",
    "    # Splitting the dataset into a Training dataset and a Test dataset.\n",
    "    X = pd.DataFrame(v['Views'])\n",
    "    y = pd.DataFrame(v['hasTop20'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2)\n",
    "    print(\"This is the Train-Test Split for the data points categorised under \" + k)\n",
    "    print(\"Train Set :\", y_train.shape, X_train.shape)\n",
    "    print(\"Test Set  :\", y_test.shape, X_test.shape)\n",
    "\n",
    "    # Decision Tree using Train Data\n",
    "    dectree = DecisionTreeClassifier(max_depth = 3)  # create the decision tree object with max depth 3\n",
    "    dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "    # Predict hasTop20 values corresponding to Views\n",
    "    y_train_pred = dectree.predict(X_train)\n",
    "    y_test_pred = dectree.predict(X_test)\n",
    "    \n",
    "    # Create a joint dataframe by concatenating Views and hasTop20\n",
    "    trainDF = pd.concat([X, y], axis = 1).reindex(X.index)\n",
    "\n",
    "    # Joint Swarmplot of Views Train against hasTop20 Train\n",
    "    print(\"\\nThis is the swarmplot of Views Train against hasTop20 Train.\")\n",
    "    f = plt.figure(figsize=(24, 6))\n",
    "    sb.swarmplot(x = \"Views\", y = \"hasTop20\", data = trainDF, orient = \"h\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting the Decision Tree\n",
    "    print(\"\\nThis is the decision tree after training.\")\n",
    "    f = plt.figure(figsize = (12,12))\n",
    "    plot_tree(dectree, filled = True, rounded = True, feature_names = X_train.columns, class_names = [\"no top 20\",\"has top 20\"])\n",
    "    plt.show()\n",
    "    \n",
    "    # Check the Goodness of Fit (on Train Data)\n",
    "    print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "    print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "    print(\"False Negative Rate\\t\\t:\", calFNR(y_train, y_train_pred))\n",
    "    print(\"True Negative Rate\\t\\t:\", calTNR(y_train, y_train_pred))\n",
    "    print()\n",
    "    print(\"False Positive Rate\\t\\t:\", calFPR(y_train, y_train_pred))\n",
    "    print(\"True Positive Rate\\t\\t:\", calTPR(y_train, y_train_pred))\n",
    "    print()\n",
    "\n",
    "    # Check the Goodness of Fit (on Test Data)\n",
    "    print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "    print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "    print(\"False Negative Rate\\t\\t:\", calFNR(y_test, y_test_pred))\n",
    "    print(\"True Negative Rate\\t\\t:\", calTNR(y_test, y_test_pred))\n",
    "    print()\n",
    "    print(\"False Positive Rate\\t\\t:\", calFPR(y_test, y_test_pred))\n",
    "    print(\"True Positive Rate\\t\\t:\", calTPR(y_test, y_test_pred))\n",
    "    print()\n",
    "\n",
    "    # Plot the Confusion Matrix for Train and Test\n",
    "    print(\"\\nThis is the corresponding Confusion Matrix for both Train and Test.\")\n",
    "    print(\"Train is on the left. Test is on the right.\")\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "               annot = True, fmt = \".0f\", annot_kws = {\"size\": 18}, ax = axes[0])\n",
    "    sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "               annot = True, fmt = \".0f\", annot_kws = {\"size\": 18}, ax = axes[1])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e20ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RFFunc()\n",
    "This function is used to generate an entire Random Forest Classification Model. It includes the train-test\n",
    "splitting of the dataset, plots out the associated figures, and prints out the goodness of fit of the given model.\n",
    "\n",
    "@param DF is the dataframe that we intend to analyse.\n",
    "@param categoryList is the list of categories that we are analysing.\n",
    "\"\"\"\n",
    "\n",
    "def RFFunc(DF, categoryList):\n",
    "    # Extract Response and Predictors\n",
    "    y = pd.DataFrame(DF['Category'].astype('category'))\n",
    "    X = pd.DataFrame(DF['Subscribers']) \n",
    "    \n",
    "    # Split the Dataset into Train and Test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 14)\n",
    "    print(\"This is the Train-Test Split for the data points:\")\n",
    "    print(\"Train Set :\", y_train.shape, X_train.shape)\n",
    "    print(\"Test Set  :\", y_test.shape, X_test.shape)\n",
    "    \n",
    "    # Draw the distribution of Response\n",
    "    plt.figure()\n",
    "    sb.catplot(y = \"Category\", data = y_train, kind = \"count\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Relationship between Response and the Predictors\n",
    "    trainDF = pd.concat([y_train, X_train], axis = 1).reindex(y_train.index)\n",
    "\n",
    "    f = plt.figure(figsize=(18, 42))\n",
    "    sb.boxplot(x = \"Subscribers\", y = \"Category\", data = trainDF, orient = \"h\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Random Forest using Train Data\n",
    "    rforest = RandomForestClassifier(n_estimators = 100, max_depth = 7)  # create the object\n",
    "    rforest.fit(X_train, y_train.values.ravel())                         # train the model\n",
    "\n",
    "    # Predict Response corresponding to Predictors\n",
    "    y_train_pred = rforest.predict(X_train)\n",
    "    y_test_pred = rforest.predict(X_test)\n",
    "    \n",
    "    # Check the Goodness of Fit (on Train Data)\n",
    "    print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "    print(\"Classification Accuracy \\t:\", rforest.score(X_train, y_train))\n",
    "    print()\n",
    "\n",
    "    # Check the Goodness of Fit (on Test Data)\n",
    "    print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "    print(\"Classification Accuracy \\t:\", rforest.score(X_test, y_test))\n",
    "    print()\n",
    "\n",
    "    # Plot the Confusion Matrix for Train and Test\n",
    "    f, axes = plt.subplots(2, 1, figsize=(12, 24))\n",
    "    sb.heatmap(confusion_matrix(y_train, y_train_pred), annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "    sb.heatmap(confusion_matrix(y_test, y_test_pred), annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "    \n",
    "    matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    matrix = matrix.astype('float') / matrix.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "    # Build the plot\n",
    "    plt.figure(figsize = (16,7))\n",
    "    sb.set(font_scale = 1.4)\n",
    "    sb.heatmap(matrix, annot = True, annot_kws = {'size':10}, cmap = plt.cm.Greens, linewidths = 0.2)\n",
    "\n",
    "    # Add labels to the plot\n",
    "    class_names = categoryList\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    tick_marks2 = tick_marks + 0.5\n",
    "    plt.xticks(tick_marks, class_names, rotation = 25)\n",
    "    plt.yticks(tick_marks2, class_names, rotation = 0)\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Confusion Matrix for Random Forest Model')\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d73d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
